---
title: "Comparing Sampling Plans through SBA Loan Data"
subtitle: "Presented for STA 490"  
author: 
  - "Alice Xiang"
  - "Joshua Zhong"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#1381B0",
  secondary_color = "#FF961C",
  inverse_header_color = "#FFFFFF"
)
```

## Table of contents

- Introduction to the Dataset
- Identifying a Stratification Variable
- Research Question
- Sampling Plans
- Performance Analysis
- Interpretation
- Conclusion

---

class: inverse center middle

## Introduction to the Dataset

---

## Introduction 

- How data was collected
- Variable Inspection
- Response Variable

---

## Identifying A Stratification Variable 

- Stratify by US Census Bureau regions
- Similarities within each region

<center><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Census_Regions_and_Division_of_the_United_States.svg/390px-Census_Regions_and_Division_of_the_United_States.svg.png" alt="State Regions" height="400px" /></center>

---

## Data Preprocessing 

- Removal of certain observations
<ul>
  <li> MIS_Status </li>
  <li> State </li>
  <li> Zip Code </li>
</ul>
- Approval Date

```{r}
## load packages
if (!require("knitr")) {
   install.packages("knitr")
   library(knitr)
}
if (!require("leaflet")) {
   install.packages("leaflet")
   library(leaflet)
}
if (!require("EnvStats")) {
   install.packages("EnvStats")
   library(EnvStats)
}
if (!require("MASS")) {
   install.packages("MASS")
 library(MASS)  
}
if (!require("phytools")) {
   install.packages("phytools")
   library(phytools)
}
if (!require("pander")) {
   install.packages("pander")
   library(pander)
}

if (!require("psych")) {   
  install.packages("psych")
   library(psych)
}
if (!require("tidyverse")) {   
  install.packages("tidyverse")
   library(tidyverse)
}
if (!require("nleqslv")) {
   install.packages("nleqslv")
   library(nleqslv)
}
if (!require("car")) {
   install.packages("car")
   library(car)
}

if (!require("kableExtra")) {
   install.packages("kableExtra")
   library(kableExtra)
}

if (!require("ggplot2")) {
   install.packages("ggplot2")
   library(ggplot2)
}

if (!require("plotly")) {
   install.packages("plotly")
   library(plotly)
}

if (!require("leaflet")) {
   install.packages("leaflet")
   library(leaflet)
}

if (!require("ggmap")) {
   install.packages("ggmap")
   library(ggmap)
}

if (!require("zipcodeR")) {
   install.packages("zipcodeR")
   library(zipcodeR)
}


url <- "https://raw.githubusercontent.com/JZhong01/STA490/main/Week9/zip_code_database.csv"

zip_code_database <- read.csv(url, stringsAsFactors = FALSE)


## read in loan dataset
loan01 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational01.csv", header = TRUE)[, -1]
loan02 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational02.csv", header = TRUE)[, -1]
loan03 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational03.csv", header = TRUE)[, -1]
loan04 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational04.csv", header = TRUE)[, -1]
loan05 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational05.csv", header = TRUE)[, -1]
loan06 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational06.csv", header = TRUE)[, -1]
loan07 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational07.csv", header = TRUE)[, -1]
loan08 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational08.csv", header = TRUE)[, -1]
loan09 = read.csv("https://pengdsci.github.io/datasets/SBAloan/w06-SBAnational09.csv", header = TRUE)[, -1]
loan = rbind(loan01, loan02, loan03, loan04, loan05, loan06, loan07, loan08, loan09)

## Delete observations where State is missing
loan <- loan[!(loan$State %in% ""),]

## Define stratification variable Region
loan <- loan %>% mutate(
  Region = case_when(
    State %in% c("MA", "ME", "VT", "NH", "CT", "RI") ~ "Northeast",
    State %in% c("NY", "PA", "NJ") ~ "Middle Atlantic",
    State %in% c("WV", "MD", "DE", "DC", "VA", "NC", "GA", "FL", "SC") ~ "South Atlantic",
    State %in% c("KY", "TN", "AL", "MS") ~ "East South Central", 
    State %in% c("OK", "AR", "LA", "TX") ~ "West South Central",
    State %in% c("OH", "IN", "IL", "MI", "WI") ~ "East North Central",
    State %in% c("MN", "IA", "MO", "KS", "NE", "SD", "ND") ~ "West North Central",
    State %in% c("MT", "WY", "CO", "UT", "AZ", "NM","NV", "ID") ~ "Mountain",
    State %in% c("AK", "OR", "CA", "AK", "HI","WA") ~ "Pacific",
    TRUE ~ "Other"
  )
)
loan$MIS_Status[loan$MIS_Status == ""] <- NA
loan <- na.omit(loan)

zip_code_database$zip <- sprintf("%05d", zip_code_database$zip)
loan$Zip <- sprintf("%05d", loan$Zip)

loan <- loan[loan$Zip %in% zip_code_database$zip, ]

initial_table <- loan %>% 
  group_by(Region) %>% 
  summarize(Count = n())

loan$ApprovalDate2 <- as.Date(loan$ApprovalDate, format="%d-%b-%y")


loan <- loan %>%
  mutate(ApprovalDate2 = if_else(year(ApprovalDate2) > 2015, 
                                ApprovalDate2 - years(100), 
                                ApprovalDate2))



kable(initial_table, caption = "Observations by Region") %>%
  kable_styling() %>%
  scroll_box(height = "300px")
  





```

---

class: inverse center middle

## Research Question

---

class: center middle

### <span style= "font-size:36px; color: black;"> What is the most effective sampling plan for accurately calculating SBA loan default rates when the data is stratified by US Census Bureau regions? </span>

---

class: inverse center middle

## Sampling Plans

---

## Sampling plans

- All samples of around 3000 observations, without replacement
- Study Population
- Four sampling plans
  - Simple Random Sample
  - Systematic Sample
  - Stratified Sample
  - Cluster Sample

---

## Visualizing our Sampling Plans

<center><img src="https://www.qualtrics.com/m/assets/wp-content/uploads/2022/02/1381633_SystemicRandomSamplingRefresh_01-560x315_060722.png" alt="Sampling Plans Visual" height="500px" /></center>


---

## Simple Random Sample

- Random 3000 observations from the dataset

```{r}
loan$sampling.frame = 1:length(loan$GrAppv)   
# sampling list
# names(study.pop)                                     
# checking the sampling list variable
sampled.list = sample(1:length(loan$GrAppv), 3000) 
# sampling the list
SRS.sample = loan[sampled.list,]                  
# extract the sampling units (observations)
## dimension check
dimension.SRS = dim(SRS.sample)
names(dimension.SRS) = c("Sample Size", "Variable Count")
kable(t(dimension.SRS))   # checking the sample size

```

---

## Systematic Random Sample

- Ordered by Approval Date
- First number chosen randomly
- Jump size

```{r}
loan_ordered <- loan[order(loan$ApprovalDate2), ]

jump.size = dim(loan_ordered)[1]%/%3000  
# find the jump size in the systematic sampling
# jump.size
rand.starting.pt=sample(1:jump.size,1) # find the random starting value
sampling.id = seq(rand.starting.pt, dim(loan_ordered)[1], jump.size)  # sampling IDs
#length(sampling.id)
sys.sample=loan_ordered[sampling.id,]    
# extract the sampling units of systematic samples
sys.Sample.dim = dim(sys.sample)
names(sys.Sample.dim) = c("Sample Size", "Variable count")
kable(t(sys.Sample.dim))

```

---

## Cluster Sampling

- Unique Zip Code as cluster 
- Two-stage cluster sampling


```{r}


unique_zips <- unique(loan$Zip)


#average_cluster_size <- mean(table(loan$Zip)) # 28.87
#num_clusters_needed <- 3000 %/% average_cluster_size #103


selected_clusters <- sample(unique_zips, 150)



cluster_sample <- loan[loan$Zip %in% selected_clusters, ]


actual_sample_size <- nrow(cluster_sample)

summary_df2 <- data.frame(Cluster = character(), 
                         InitialSize = integer(), 
                         FinalSize = integer(), 
                         Proportion = numeric())


if(actual_sample_size >= 2950 && actual_sample_size <= 3050){
  # desired sample size, nothing happens
  
}else{
  prop_of_cluster <- 3000 / actual_sample_size
  final_cluster_sample <- data.frame()
  
  for (zip in selected_clusters) { 
    
    # calculate number of values to be sampled from zip by looking at
    # proportion_of_cluster * sample size of each cluster then take 
    # ceiling. Take random sample of each cluster based off this calculation
    
    cluster_data <- cluster_sample[cluster_sample$Zip == zip, ]
    
    num_to_sample <- round(nrow(cluster_data) * prop_of_cluster)
    


    cluster_sample_subset <- cluster_data[sample(1:nrow(cluster_data), num_to_sample), ]
    

    final_cluster_sample <- rbind(final_cluster_sample, cluster_sample_subset)
    
    }
  
}

final_sample_size <- nrow(final_cluster_sample)

proportion_needed <- 3000 / actual_sample_size

summary_df <- data.frame(ActualSampleSize = actual_sample_size,
                         ProportionNeeded = proportion_needed, 
                         FinalSampleSize = final_sample_size)

kable(summary_df, 
      caption = "Actual Sample Size and Proportion Needed",
      col.names = c("Actual Sample Size", "Proportion Needed", "Final Sample Size"))


for (zip in selected_clusters) {
  cluster_data <- cluster_sample[cluster_sample$Zip == zip, ]
  initial_size <- nrow(cluster_data)
  final_size <- round(initial_size * prop_of_cluster)
  
  # Adjust final_size to not exceed initial_size
  final_size <- min(final_size, initial_size)
  
  # Add the cluster summary to the summary data frame
  summary_df2 <- rbind(summary_df2, data.frame(ZipCode = zip, 
                                             InitialSize = initial_size, 
                                             FinalSize = final_size, 
                                             Proportion = final_size / initial_size))
}

# Display the summary data frame using kable

kable(summary_df2, "html") %>%
  kable_styling() %>%
  scroll_box(height = "300px")


```

---

## Cluster Visual

```{r out.width = '100%', fig.height = 7}

#selected_clusters is vector of cluster sampled zip_codes
# zip_code_database is our .csv file

#register_google(key = "AIzaSyDZJFOkJmUMS1zUpeH_K-1sGaw_1As8YvI", write = FALSE)


final_cluster_sample <- final_cluster_sample %>%
  left_join(zip_code_database %>% select(zip, latitude, longitude),
            by = c('Zip' = 'zip'))

# Count the number of observations per ZIP code
zip_counts <- final_cluster_sample %>%
  group_by(Zip) %>%
  summarize(ObservationCount = n())

# Left join
#final_cluster_sample <- final_cluster_sample %>%
  #left_join(zip_counts, by = "Zip")

min_size <- 4
max_size <- 21

# Find the maximum number of observations to scale point sizes
max_count <- max(zip_counts$ObservationCount)
min_count <- min(zip_counts$ObservationCount)

# Scale sizes to range from min_size to max_size
zip_counts$scaled_size <- (zip_counts$ObservationCount - min_count) / 
                          (max_count - min_count) * 
                          (max_size - min_size) + min_size

# Join the scaled size back to the final_cluster_sample
final_cluster_sample <- merge(final_cluster_sample, zip_counts, by = "Zip")

# Create the leaflet map
leaflet(final_cluster_sample) %>%
  addProviderTiles(providers$Esri.NatGeoWorldMap) %>%
  addCircleMarkers(
    lng = ~longitude, lat = ~latitude,
    radius = ~scaled_size,  # Use the scaled size
    popup = ~paste("ZIP:", Zip, "<br/>Count:", ObservationCount),
    fillColor = "#007bff",
    fillOpacity = 0.8,
    stroke = FALSE
) 

```

---

## Stratified Random Sample

- Grouped by Region as strata
- Proportional strata

Table of subpopulation sizes: 

```{r}
freq.table = table(loan$Region)  # frequency table of strNAICS
rel.freq = freq.table/sum(freq.table)   # relative frequency 
strata.size = round(rel.freq*3000) # strata size allocation
strata.names=names(strata.size)

strata.size.df = as.data.frame(strata.size)

colnames(strata.size.df) <- c("Region", "Freq")

kable(strata.size.df, col.names = c("Region", "Freq"))

strata.sample = loan[1,]    # create a reference data frame
strata.sample$add.id = 1   # add a temporary ID to because in the loop
                           # i =2 testing a single iteration
for (i in 1:length(strata.names)){
   ith.strata.names = strata.names[i]   # extract data frame names
   ith.strata.size = strata.size[i]     # allocated stratum size
   # The following code identifies observations to be selected
   ith.sampling.id = which(loan$Region==ith.strata.names) 
   ith.strata = loan[ith.sampling.id,]  # i-th stratified population
   ith.strata$add.id = 1:dim(ith.strata)[1]  # add sampling list/frame
   # The following code generates a subset of random ID
   ith.sampling.id = sample(1:dim(ith.strata)[1], ith.strata.size) 
   ## Create a selection status -- pay attention to the operator: %in% 
   ith.sample =ith.strata[ith.strata$add.id %in%ith.sampling.id,]
   ## dim(ith.sample)         $ check the sample
   strata.sample = rbind(strata.sample, ith.sample)  # stack all data frame!
 }
 # dim(strata.sample)
 strat.sample.final = strata.sample[-1,]  # drop the temporary stratum ID
 # kable(head(strat.sample.final))         # accuracy check!

```


---

class: inverse center middle

## Performance Analysis 

---

## Population Default rates

- Performance Metric
- Calculations

```{r}
x.table = table(loan$Region, loan$MIS_Status)
default = x.table[,1]
no.default = x.table[,2]
default.rate = round(100*default/(default+no.default),1)
default.status.rate = cbind(default = default, 
                            no.default = no.default,
                            default.rate=default.rate)
 
kable(default.status.rate, caption = "Population size, default counts, 
                                      and population default rates")

```


---

## Sample Default Rates

Then, we calculate the default rates for each sampling plan. 

```{r}

## SRS default rates 
x.table = table(SRS.sample$Region, SRS.sample$MIS_Status)
default.srs = x.table[,1]
no.default.srs = x.table[,2]
default.rate.srs = round(100*default.srs/(default.srs+no.default.srs),1)

state.code = names(default.rate.srs)  
state.name=c("East North Central","East South Central","Middle Atlantic","Mountain","Northeast","Pacific","South Atlantic","West North Central","West South Central")
default.rate.pop = default.rate[state.code]
# cbind(industry.code,industry.name)



## Systematic sample default rates
x.table = table(sys.sample$Region, sys.sample$MIS_Status)
default.sys = x.table[,1]
no.default.sys = x.table[,2]
default.rate.sys = round(100*default.sys/(default.sys+no.default.sys),1)


## Cluster sample default rates
x.table = table(final_cluster_sample$Region, final_cluster_sample$MIS_Status)
default.clu = x.table[,1]
no.default.clu = x.table[,2]
default.rate.clu = round(100*default.clu/(default.clu+no.default.clu),1)


## Stratified sample
x.table = table(strat.sample.final$Region, strat.sample.final$MIS_Status)
default.str = x.table[,1]
no.default.str = x.table[,2]
default.rate.str = round(100*default.str/(default.str+no.default.str),1)


default_rates_combined <- data.frame(
  Population = default.rate.pop[state.code],
  SRS = default.rate.srs[state.code],
  Systematic = default.rate.sys[state.code],
  Cluster = default.rate.clu[state.code],
  Stratified = default.rate.str[state.code]
)



rownames(default_rates_combined) = state.name

kable(default_rates_combined, caption="Comparing Default Rates between Population and Our Sampling Plans")

```

---

## Visualizing our Default Rates


```{r}


rate_data <- data.frame(
  Region = state.code,
  Population = as.vector(default.rate.pop),
  SRS = as.vector(default.rate.srs),
  Systematic = as.vector(default.rate.sys),
  Cluster = as.vector(default.rate.clu),
  Stratified = as.vector(default.rate.str)
)


long_data <- tidyr::pivot_longer(rate_data, cols = -Region, names_to = "SampleType", values_to = "DefaultRate")

ggplot_obj <- ggplot(long_data, aes(x = Region, y = DefaultRate, color = SampleType, group = SampleType)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "Comparison of Default Rates",
       x = "", y = "Default Rate") +
  scale_color_discrete(name = "Sample Type") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  
    plot.margin = margin(5.5, 100, 5.5, 5.5)  
  )


ggplot_obj <- ggplot_obj + theme(aspect.ratio = 1/3)  # Adjust aspect ratio to your preference for taller graph

# Convert ggplot object to plotly interactive object
interactive_plot <- ggplotly(ggplot_obj, tooltip = "text")

# Customize the layout for plotly to make the plot taller
interactive_plot <- interactive_plot %>% layout(autosize = TRUE, width = 1100, height = 500)  # Adjust height as needed

# Print the interactive plot
interactive_plot

```


---

class: inverse center middle

## Conclusions

---

## Interpretations

- Recommendations
  - Statistical
  - Practical
  
- Verdict

- Limitations